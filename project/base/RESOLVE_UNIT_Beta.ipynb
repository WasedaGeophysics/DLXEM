{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\mathrm{RESOLVE \\space UNIT \\space \\beta}$\n",
    "## 周波数領域電磁探査法(RESOLVE)データの深層学習を用いた水平多層構造解析\n",
    "入力セルを編集後、全てのセルを実行してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各種ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import json\n",
    "import sys, os\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sys.path.append('../../')\n",
    "from script import emexecutor as em\n",
    "from script import networks, forward\n",
    "from script.tools import thicks_maker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 入力セル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ニューラルネットワークの名前\n",
    "dnn_name = 'sample'\n",
    "\n",
    "\"\"\"\n",
    "層厚の設定\n",
    "　学習データの生成から地下構造の内、層数と層厚は固定されます。\n",
    "　入力値は層数、表層の厚さ、最終層の上端深度、層厚の等分割スケールの４つです。\n",
    "　全n層の内、表層と最終層の間は線形スケールまたは対数スケールで(n-2)等分されます。\n",
    "　一層ずつ手入力で決めることもできます。\n",
    "\"\"\"\n",
    "# 層数\n",
    "nlayer = 30\n",
    "\n",
    "# 表層の厚さ\n",
    "init_thick = 0.5\n",
    "\n",
    "# 最終層の上端深度\n",
    "last_depth = 150\n",
    "\n",
    "# 層厚のスケール (対数スケール：'log' / 線形スケール：'linear')\n",
    "split_scale = 'log'\n",
    "\n",
    "# 層厚の手入力 on/off : manual_input = True / off : manual_input = False\n",
    "manual_input = False\n",
    "\n",
    "# 層厚の手入力 e.g.) thicks = [100, 10, 100]\n",
    "thicks = None\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "人口学習データの生成とRESOLVEに関する設定\n",
    "\"\"\"\n",
    "# 学習に用いる比抵抗構造-磁場応答データの数\n",
    "size = 10000\n",
    "\n",
    "# 生成する比抵抗の平均値 (Ohm-m)\n",
    "res_mean = 100\n",
    "\n",
    "# RESOLVEの測定周波数(昇順, Hz)\n",
    "freqs = [340, 1500, 6600, 31000, 140000]\n",
    "\n",
    "# バード高さの下限 (m)\n",
    "height_min = 10\n",
    "\n",
    "# バード高さの上限 (m)\n",
    "height_max = 100\n",
    "\n",
    "# コイル間のオフセット (m)\n",
    "offset = 7.86\n",
    "\n",
    "# ノイズの付与　on : = True, off : = False\n",
    "add_noise = True\n",
    "\n",
    "# ノイズレベル（付与するノイズの標準偏差, ppm)\n",
    "noise_level = [10, 10, 20, 40, 50]\n",
    "\n",
    "# 比抵抗構造生成モード 現状、'normal'で固定\n",
    "generate_mode = 'normal'\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "ニューラルネットワークの学習に関する設定\n",
    "　★おすすめ設定その１ (精度重視)\n",
    "    batch_size = size ÷ 50\n",
    "    epochs = 200 ~ 300\n",
    "　★おすすめ設定その２（時短重視）\n",
    "    batch_size = size ÷ 100 \n",
    "    epochs = 100\n",
    "\"\"\"\n",
    "# バッチサイズ　値が大きいほど学習時間は短くなります。\n",
    "batch_size = 400\n",
    "# エポック回数 値が小さいほど学習時間が短くなります。\n",
    "epochs = 50\n",
    "\n",
    "\"\"\"\n",
    "深層学習解析を適用するフィールドデータの入力\n",
    "\"\"\"\n",
    "# 探査プロジェクト名（自由）\n",
    "field_name = 'touhoku'\n",
    "# データは表形式\n",
    "# CSV / XYZ から選べる\n",
    "datafile_format = 'CSV'\n",
    "\n",
    "# データファイルのパス\n",
    "data_directory = \"database/survey/HEM_line_base_mini.csv\"\n",
    "\n",
    "# TXTの場合の冒頭スキップ行数\n",
    "skiprows = 8\n",
    "\n",
    "# 使用するデータ列の列番号\n",
    "#  測線番号, Easting (m), Northing (m), 地表面標高 (m), HCP5種同相成分 (ppm), HCP5種離相成分 (ppm), バード高さ\n",
    "#  ※ 同相成分、離相成分は周波数の昇順にします。\n",
    "#  ※ 3300HzVCAコイルのデータは除外することに注意してください。\n",
    "pickup_columns = [1, 4, 5, 8, 26, 25, 23, 22, 21, 32, 31, 29, 28, 27, 6]\n",
    "\n",
    "# 測定データファイルの欠損オブジェクト\n",
    "nan_char = '*'\n",
    "\n",
    "# 保存先のパス、ファイル名\n",
    "# database/result/~.csv\n",
    "save_path = \"database/result/{}_result_by_{}.csv\".format(field_name, dnn_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 層構造の決定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"] = 18\n",
    "plt.tight_layout()\n",
    "if manual_input:\n",
    "    thicks = np.array(thicks)\n",
    "    depth = [0]\n",
    "    for t in thicks:\n",
    "        depth.append(depth[-1] + t)\n",
    "    depth = np.array(depth)\n",
    "    print('層境界深度')\n",
    "    for i in depth:\n",
    "        print(round(i, 3) ,end=' m | ')\n",
    "\n",
    "else:\n",
    "    thicks, depth = thicks_maker(init_thick, last_depth, nlayer, split_scale)\n",
    "    plt.show()\n",
    "    print('層境界深度')\n",
    "    for i in depth:\n",
    "        print(round(i, 3) ,end=' m | ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. データ生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定の保存\n",
    "settings = {\n",
    "    'dnn_name' : dnn_name,\n",
    "    'nlayer' : nlayer,\n",
    "    'init_thick' : init_thick,\n",
    "    'last_depth' : last_depth,\n",
    "    'split_scale' : split_scale,\n",
    "    'manual_input' : manual_input,\n",
    "    'thicks' : thicks,\n",
    "    'size' : size,\n",
    "    'res_mean' : res_mean,\n",
    "    'freqs' : freqs,\n",
    "    'height_min' : height_min,\n",
    "    'height_max' : height_max,\n",
    "    'offset' : offset,\n",
    "    'add_noise' : add_noise,\n",
    "    'noise_level' : noise_level,\n",
    "    'generate_mode' : generate_mode,\n",
    "    'batch_size' : batch_size,\n",
    "    'epochs' : epochs,\n",
    "    'field_name' : field_name,\n",
    "    'datafile_format' : datafile_format,\n",
    "    'data_directory' : data_directory,\n",
    "    'skiprows' : skiprows,\n",
    "    'pickup_columns' : pickup_columns,\n",
    "    'nan_char' : nan_char,\n",
    "    'save_path' : save_path\n",
    "}\n",
    "with open('database/result/{}_{}_settings.json'.format(field_name, dnn_name), 'w') as fp:\n",
    "    json.dump(settings, fp)\n",
    "\n",
    "config = {\n",
    "    'thicks' : thicks,\n",
    "    'rmean' : np.log10(res_mean),\n",
    "    'rscat' : 1.0,\n",
    "    'height_range' : (height_min, height_max),\n",
    "    'freqs' : freqs,\n",
    "    'span' : offset,\n",
    "    'add_noise' : add_noise,\n",
    "    'noise_level' : noise_level,\n",
    "    'random_mode' : generate_mode\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parallel_num = 10\n",
    "\n",
    "nlayer = len(thicks) + 1\n",
    "dataset_dir = 'database/dataset/'\n",
    "dsetfile_path = dataset_dir + dnn_name + '_{}_{}.csv'.format(nlayer, size)\n",
    "\n",
    "model_dir = 'model/'\n",
    "histfile_path = model_dir + 'history/' + dnn_name + 'history.csv'\n",
    "nnetfile_path = model_dir + 'network/' + dnn_name + 'network.h5'\n",
    "\n",
    "\n",
    "if os.path.exists(dsetfile_path):\n",
    "    df = pd.read_csv(dsetfile_path, header=None)\n",
    "    print('Datasets already exist')\n",
    "else:\n",
    "    resolve = em.Resolve1D(**config)\n",
    "    data = resolve.multi_process(size, parallel_num)\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(dsetfile_path, header=None, index=False)\n",
    "    print(\"-> /\" + dsetfile_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ニューラルネットワークの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分割\n",
    "x = df.iloc[:, :11].values\n",
    "y = df.iloc[:, 11:].values\n",
    "y = np.log10(y)\n",
    "x_train, x_val_test, y_train, y_val_test = train_test_split(x, y, test_size=0.02, random_state=0)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val_test, y_val_test, test_size=0.5, random_state=0)\n",
    "x_test_org = x_test.copy()\n",
    "\n",
    "#x正規化\n",
    "sc = preprocessing.StandardScaler()\n",
    "sc.fit(x_train)\n",
    "x_train = sc.transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "x_val = sc.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(nnetfile_path):\n",
    "    print('The Specified Neural Network Model Already Exists.')\n",
    "    network = load_model(nnetfile_path)\n",
    "    hist_df = pd.read_csv(histfile_path)\n",
    "else:\n",
    "    input_dim = x.shape[1]\n",
    "    output_dim = y.shape[1]\n",
    "    network = networks.get_dnn(input_dim, output_dim)\n",
    "    history = network.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=2, validation_data=(x_val, y_val))\n",
    "    network.save(nnetfile_path)\n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    hist_df.to_csv(histfile_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 評価・テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"] = 18\n",
    "plt.tight_layout()\n",
    "epochx = np.arange(1, epochs+1)\n",
    "val_mse = hist_df['val_loss'].values\n",
    "loss = hist_df['loss'].values\n",
    "fig = plt.figure(figsize=(20,8))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.plot(epochx, loss, label='train loss', linewidth=2)\n",
    "ax1.plot(epochx, val_mse, label='validation loss', linewidth=2)\n",
    "ax1.set_xlabel('epochs')\n",
    "ax1.set_ylabel('MSE')\n",
    "ax1.set_xlim(0, epochx.max())\n",
    "ax1.set_ylim(0, loss.max() // 1 + 1)\n",
    "ax1.legend()\n",
    "ax1.grid()\n",
    "ax1.set_title('Loss Transition', fontsize = 20)\n",
    "\n",
    "terr = (y_test - network.predict(x_test))**2\n",
    "res_mse = np.array([k.mean() for k in terr])\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "max_mse = res_mse.max()\n",
    "nbins = int(max_mse // 0.1)\n",
    "bins = [.1*(i) for i in range(nbins)]\n",
    "n, bins, patches = ax2.hist(res_mse, bins=bins, edgecolor='k')\n",
    "y2 = np.add.accumulate(n) / n.sum() * 100\n",
    "x2 = np.convolve(bins, np.ones(2) / 2, mode=\"same\")[1:]\n",
    "ax2.set_xlabel('MSE')\n",
    "ax2.set_ylabel('number of data')\n",
    "mean = np.mean(res_mse)\n",
    "median = np.median(res_mse)\n",
    "ax2.set_ylim(0, n.max()+10)\n",
    "ax2.set_title('Mean: {mean:.2f}, Median: {median:.2f}'.format(mean=mean, median=median))\n",
    "\n",
    "# 第2軸のプロット\n",
    "bx2 = ax2.twinx()\n",
    "lines = bx2.plot(x2, y2, ls='-', color='C1', linewidth=3, label='Cumulative ratio')\n",
    "bx2.set_ylim(10 * y2.min() // 10, 105)\n",
    "bx2.set_ylabel('Cumulative ratio [%]')\n",
    "bx2.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../')\n",
    "from script import myviz as viz\n",
    "true_res = 10 ** y_test\n",
    "pred_res = 10 ** network.predict(x_test)\n",
    "orig_emf = x_test_org[:, :10]\n",
    "height = x_test_org[:, 10]\n",
    "\n",
    "test_data_size = len(y_test)\n",
    "index = np.random.randint(0, test_data_size)\n",
    "\n",
    "true_res = true_res[index]\n",
    "pred_res = pred_res[index]\n",
    "height = height[index]\n",
    "orig_emf = orig_emf[index]\n",
    "\n",
    "cfreq_range = (0, 8)\n",
    "print(index)\n",
    "\n",
    "fig = viz.resolve.sumplot(\n",
    "    thicks, pred_res, true_res, height, offset, freqs, cfreq_range, orig_emf, noised=add_noise, log_depth=True\n",
    ")\n",
    "fig.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "fig.axes[0].set_yscale('log');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. DL解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pickup_columns)):\n",
    "    pickup_columns[i] -= 1\n",
    "\n",
    "header = ['line No.', 'easting', 'northing', 'elevation', 'EM1R', 'EM2R', 'EM3R', 'EM4R', 'EM5R', 'EM1I', 'EM2I', 'EM3I', 'EM4I', 'EM5I', 'bird_height']\n",
    "dnnx_index = ['EM1R', 'EM2R', 'EM3R', 'EM4R', 'EM5R', 'EM1I', 'EM2I', 'EM3I', 'EM4I', 'EM5I', 'bird_height']\n",
    "loc_index = ['line No.', 'easting', 'northing', 'elevation']\n",
    "\n",
    "if os.path.exists(save_path):\n",
    "    print('the result has already saved.')\n",
    "    pass\n",
    "\n",
    "else:\n",
    "    if datafile_format == 'XYZ':\n",
    "        data = np.loadtxt(data_directory, skiprows=skiprows)\n",
    "        dfd = data[:, pickup_columns]\n",
    "        df = pd.DataFrame(dfd, columns=header)\n",
    "\n",
    "    elif datafile_format == 'CSV':\n",
    "        data = pd.read_csv(data_directory)\n",
    "        dfd = data.iloc[:, pickup_columns].values\n",
    "        df = pd.DataFrame(dfd, columns=header)\n",
    "\n",
    "    # 欠損値を含む行\n",
    "    df = df.replace(nan_char, np.nan)\n",
    "    df = df.dropna(how='any')\n",
    "    x = df[dnnx_index].values\n",
    "    loc = df[loc_index].values\n",
    "\n",
    "    stdx = sc.transform(x)\n",
    "    res = network.predict(stdx)\n",
    "    res = 10 ** res\n",
    "\n",
    "    numlayer = len(depth)\n",
    "    res_header = ['R{}'.format(i+1) for i in range(numlayer)]\n",
    "    header = [*header, *res_header]\n",
    "    rdata = np.hstack([loc, x, res])\n",
    "    rdf = pd.DataFrame(rdata)\n",
    "    rdf.to_csv(save_path, header=header, index=False)\n",
    "    print('the result is saved at ' + save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(save_path)\n",
    "lines = df['line No.'].values\n",
    "line_no_list = []\n",
    "logg = 0\n",
    "for nomb in lines:\n",
    "    if nomb == logg:\n",
    "        logg = nomb\n",
    "    else:\n",
    "        line_no_list.append(nomb)\n",
    "        logg = nomb\n",
    "print('測線番号リスト')\n",
    "print(line_no_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 比抵抗断面図の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineno = line_no_list[3]\n",
    "\n",
    "dfch = df[df['line No.']==lineno]\n",
    "emdfx = dfch.loc[:, 'easting':'bird_height']\n",
    "redfx = dfch.loc[:, 'R1':]\n",
    "\n",
    "easting = emdfx['easting'].values\n",
    "nrothing = emdfx['northing'].values\n",
    "elevation = emdfx['elevation'].values\n",
    "height = emdfx['bird_height'].values\n",
    "\n",
    "res = redfx.values\n",
    "res = np.log10(res)\n",
    "\n",
    "resmax = np.log10(1000)\n",
    "resmin = res.min()\n",
    "cres = (res-resmin)/(resmax-resmin)\n",
    "cmaps = plt.cm.jet_r(cres)\n",
    "\n",
    "depthadd = np.append(depth, 2*depth.max())\n",
    "plt.style.use('default')\n",
    "fig = plt.figure(figsize=(20, 3), dpi=100)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.grid()\n",
    "ax.set(xlim=(easting.min(), easting.max()), ylim=(-depth.max()+elevation.min()-50, height.max()+100))\n",
    "for i in range(easting.shape[0]-1):\n",
    "    mesh_x, mesh_y = np.meshgrid(easting[i:i+2], -depthadd+elevation[i])\n",
    "    cross_section = ax.pcolormesh(mesh_x, mesh_y, res[i].reshape(len(res[i]), 1), vmin=resmin, vmax=resmax, cmap='jet_r', shading='flat')\n",
    "\n",
    "norm = mpl.colors.Normalize(vmin=resmin, vmax=resmax)\n",
    "m = mpl.cm.ScalarMappable(cmap=plt.cm.jet_r, norm=norm)\n",
    "m.set_array([])\n",
    "fig.colorbar(m, label='Resistivity ${\\log_{10}{ρ}}$')\n",
    "ax.plot(easting, elevation+height, color='k', label='bird')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Easting [m]')\n",
    "ax.set_ylabel('Elevation [m]')\n",
    "ax.set_title('Resistivity Structure below the Line No.{}'.format(lineno));"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c13f70dffa5cdf3bd9c6c39df9dc61a13f2ef6bb2d6b8fdd793e76224c87a417"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('dlabpy37': conda)",
   "name": "python377jvsc74a57bd0c13f70dffa5cdf3bd9c6c39df9dc61a13f2ef6bb2d6b8fdd793e76224c87a417"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "c13f70dffa5cdf3bd9c6c39df9dc61a13f2ef6bb2d6b8fdd793e76224c87a417"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}